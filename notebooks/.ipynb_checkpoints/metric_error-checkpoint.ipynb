{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb597087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import getdist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '../'))\n",
    "from metrics import diff\n",
    "from metrics import flow\n",
    "from metrics import tension\n",
    "from metrics.parameter_metrics import *\n",
    "from metrics import utilities\n",
    "from emulators import lsst\n",
    "from emulators import cosmopower\n",
    "import pybobyqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f3a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path    = '/home/grads/extra_data/evan/lsst_chains/'\n",
    "planck_path  = '/home/grads/extra_data/evan/planck_chains/'\n",
    "joint_path = '/home/grads/extra_data/evan/joint_chains/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5880e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 16:18:47.460530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: NVIDIA GeForce GT 730, pci bus id: 0000:c1:00.0, compute capability: 3.5) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-09-26 16:18:47.461090: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-26 16:18:48.182827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3375 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960, pci bus id: 0000:09:00.0, compute capability: 5.2\n",
      "2022-09-26 16:18:48.851745: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x55c08f792e90\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Open the emulators, setup functions, intial pos of optimizer\n",
    "#\n",
    "#######\n",
    "\n",
    "lsst_emulator = lsst.lsst_emulator()\n",
    "cosmopower_emulator = cosmopower.cosmopower()\n",
    "\n",
    "#priors\n",
    "priors = {'omegab':  [0.001, 0.04],\n",
    "          'omegac':  [0.005, 0.99],\n",
    "          'omegabh2':  [0.001, 0.04],\n",
    "          'omegach2':  [0.005, 0.99],\n",
    "          'h':       [0.2,   1.0],\n",
    "          'H0':      [55,    91],\n",
    "          'tau':     [0.01,  0.8],\n",
    "          'ns':      [0.9,   1.1],\n",
    "          'logAs':    [1.61,  3.91],\n",
    "          'logA':    [1.61,  3.91],\n",
    "          'Aplanck': [1.0,   0.01],\n",
    "         }\n",
    "\n",
    "### for GOF degradation need likelihoods and posterior\n",
    "\n",
    "def planck_log_prob(theta):\n",
    "    theta = np.reshape(theta.astype('float32'),(7))\n",
    "    p = cosmopower_emulator.tf_planck.posterior(np.array([theta],np.float32)).numpy()[0]\n",
    "    if( p == -1*np.inf ):\n",
    "        p = -1e32\n",
    "    return -1 * p\n",
    "\n",
    "def lsst_log_prob(theta):\n",
    "    p = lsst_emulator.log_prob(theta)\n",
    "    if( p == -1*np.inf ):\n",
    "        p = -1e32\n",
    "    return -1 * p\n",
    "\n",
    "def joint_log_prob(theta):\n",
    "    planck_idxs = [3,4,2,29,1,0,30]\n",
    "    theta_lsst = theta[:29]\n",
    "    theta_planck = np.array(theta)[planck_idxs]\n",
    "    theta_planck[2] = theta_planck[2]/100\n",
    "    lsst_prob = lsst_emulator.log_prob(theta_lsst)\n",
    "    planck_prob = cosmopower_emulator.tf_planck.posterior(np.array([theta_planck],dtype=np.float32)).numpy()[0]\n",
    "    p = ( lsst_prob + planck_prob )\n",
    "    if( p == -1*np.inf ):\n",
    "        p = -1e32\n",
    "    return -1 * p\n",
    "\n",
    "### Initial position for the optimizer\n",
    "planck_initial = [0.0225966, 0.11852284, 0.68692449, 0.12349488, 0.97225104, 3.18047929, 1.00070875]\n",
    "\n",
    "lsst_initial = np.array([3.01273691e+00, 9.58661626e-01, 7.14349796e+01, 2.55546828e-02, 1.28688739e-01, \n",
    "          0., 0., 0., 0., 0.,\n",
    "          0.5, 0.,\n",
    "          0., 0., 0., 0., 0.,\n",
    "          1.24, 1.36, 1.47, 1.60, 1.76,\n",
    "          0., 0., 0., 0., 0.,\n",
    "          0., 0.])\n",
    "\n",
    "joint_initial = np.array([3.0675, 0.97, 69.0, 0.0228528, 0.1199772, \n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      0.5, 0.,\n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      1.24, 1.36, 1.47, 1.60, 1.76,\n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      0., 0.,0.1235,1.0007])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee994c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is missing!!!\n",
      "1 is missing!!!\n",
      "20 is missing!!!\n",
      "26 is missing!!!\n",
      "37 is missing!!!\n",
      "44 is missing!!!\n",
      "64 is missing!!!\n",
      "76 is missing!!!\n",
      "78 is missing!!!\n",
      "93 is missing!!!\n",
      "153 is missing!!!\n",
      "166 is missing!!!\n",
      "184 is missing!!!\n",
      "224 is missing!!!\n",
      "233 is missing!!!\n",
      "242 is missing!!!\n",
      "243 is missing!!!\n",
      "267 is missing!!!\n",
      "273 is missing!!!\n",
      "275 is missing!!!\n",
      "278 is missing!!!\n",
      "293 is missing!!!\n",
      "405 is missing!!!\n",
      "600\n",
      "[####################] Completed!                             \n",
      "start_opt\n",
      "end_opt\n",
      "Removed no burn in\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n"
     ]
    }
   ],
   "source": [
    "### Change as needed\n",
    "overwrite = False  # If false only adds to results and reruns those with error codes\n",
    "\n",
    "_nf        = True  # If true runs this metric\n",
    "_q_udm     = True\n",
    "_q_dmap    = True\n",
    "_eigenmode = True\n",
    "\n",
    "start = 0          # range to run results\n",
    "stop = 700\n",
    "####################\n",
    "\n",
    "#open planck and lsst noise realizations\n",
    "planck_dvs = np.loadtxt('/home/grads/data/evan/planck_noise.txt')\n",
    "lsst_dvs   = np.loadtxt('/home/grads/data/evan/noisy_dvs.txt')\n",
    "\n",
    "### open results or create new results\n",
    "if overwrite:\n",
    "    results = []                           \n",
    "else:\n",
    "    try:\n",
    "        results = np.loadtxt('results.txt').tolist()\n",
    "    except:\n",
    "        print('no results.txt found!')\n",
    "        results = []\n",
    "\n",
    "### Now run the metrics\n",
    "for i in range(start,stop):\n",
    "    print('\\r'+str(i),end='')\n",
    "    try:\n",
    "        r = results[i]\n",
    "        append = False # flag that determines whether to use append or index\n",
    "        #print(r)\n",
    "        if( (np.array(r[1:])>=0).all() and len(r)>1 ):\n",
    "            continue\n",
    "        else:\n",
    "            r = [i]\n",
    "    except:\n",
    "        r = [i] # holds only this iteration results\n",
    "        #print('need to run!')\n",
    "        append = True # flag that determines whether to use append or index\n",
    "    try:\n",
    "        chain1 = getdist.mcsamples.loadMCSamples(planck_path+str(i))\n",
    "        chain2 = getdist.mcsamples.loadMCSamples(lsst_path+'lsst_'+str(i))\n",
    "        chain3 = getdist.mcsamples.loadMCSamples(joint_path+'joint_'+str(i))\n",
    "        chain1.removeBurnFraction(0.3) # forgot :(\n",
    "        chain1.weighted_thin(10)       #forgot\n",
    "    except:\n",
    "        print('\\r'+str(i)+' is missing!!!')\n",
    "        r = [i]\n",
    "        for j in range(4):\n",
    "            r.append(-3) # set all metrics to -3\n",
    "        if( append ):\n",
    "            results.append(r)\n",
    "        else:\n",
    "            results[i] = r\n",
    "        continue        # skip rest of loop\n",
    "        \n",
    "    s = chain1.samples\n",
    "    s[...,2] = 100*s[...,2]\n",
    "    chain1.setSamples(s)\n",
    "        \n",
    "    chains = diff.chain()\n",
    "    chains.chains = [chain1,chain2]     \n",
    "    chains.diff(feedback=False) # compute the difference chain\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    ### Normalizing flow\n",
    "    if _nf:     \n",
    "        maf = flow.MAF(len(chains.params))\n",
    "        maf.setup(feedback=False)\n",
    "        maf.train(chains.diff_chain,batch_size=10000,feedback=False)\n",
    "        nsigma,high,low = tension.flow_significance(\n",
    "                            maf.target_dist,\n",
    "                            maf.gauss_bijector,\n",
    "                            len(chains.params)\n",
    "                            )\n",
    "        if( np.isnan(nsigma) or nsigma==np.inf ):\n",
    "            r.append(-2)\n",
    "        else:\n",
    "            r.append(nsigma)    \n",
    "    else:\n",
    "        r.append(-1)\n",
    "        \n",
    "    ### Parameter Update\n",
    "    if _q_udm:\n",
    "        nsigma = qudm(chain2,chain3,feedback=False)\n",
    "        if( np.isnan(nsigma) or nsigma==np.inf ):\n",
    "            r.append(-2)\n",
    "        else:\n",
    "            r.append(nsigma)\n",
    "    else:\n",
    "        r.append(-1)\n",
    "        \n",
    "    ### GOF degredation\n",
    "    if _q_dmap:\n",
    "        # set noise realizations\n",
    "        print('start_opt')\n",
    "        cosmopower_emulator.X_data = planck_dvs[i]\n",
    "        lsst_emulator.dv_obs = lsst_dvs[i]\n",
    "        \n",
    "        map_a = pybobyqa.solve(planck_log_prob,planck_initial,rhobeg=0.01,rhoend=1e-12,maxfun=500)\n",
    "        lkl_a = cosmopower_emulator.tf_planck.get_loglkl(np.array([map_a.x],dtype=np.float32)).numpy()[0]\n",
    "        \n",
    "        map_b = pybobyqa.solve(lsst_log_prob,lsst_initial,rhobeg=0.01,rhoend=1e-12,maxfun=500)\n",
    "        lkl_b = lsst_emulator.log_lkl(map_b.x)\n",
    "        \n",
    "        map_ab = pybobyqa.solve(joint_log_prob,joint_initial,rhobeg=0.01,rhoend=1e-12,maxfun=500)\n",
    "        \n",
    "        planck_idxs = [3,4,2,29,1,0,30]\n",
    "        map_ab_lsst = map_ab.x[:29]\n",
    "        map_ab_planck =  map_ab.x[planck_idxs]\n",
    "        map_ab_planck[2] = map_ab_planck[2]/100\n",
    "        lkl_ab = lsst_emulator.log_lkl(map_ab_lsst)+cosmopower_emulator.tf_planck.get_loglkl(np.array([map_ab_planck],dtype=np.float32)).numpy()[0]\n",
    "        \n",
    "        print('end_opt')\n",
    "        \n",
    "        nsigma = q_dmap(chain1,chain2,chain3,prior_dict=priors,lkl_a=lkl_a,lkl_b=lkl_b,lkl_ab=lkl_ab)\n",
    "        \n",
    "        if( np.isnan(nsigma) or nsigma==np.inf ):\n",
    "            r.append(-2)\n",
    "        else:\n",
    "            r.append(nsigma)\n",
    "    else:\n",
    "        r.append(-1)\n",
    "        \n",
    "    ### eigentension\n",
    "    if _eigenmode:\n",
    "        nsigma,high,low = eigentension(chain1,chain2,priors,feedback=False)\n",
    "        if( np.isnan(nsigma) or nsigma==np.inf ):\n",
    "            r.append(-2)\n",
    "        else:\n",
    "            r.append(nsigma)\n",
    "    else:\n",
    "        r.append(-1)\n",
    "    if( append ):\n",
    "        results.append(r)\n",
    "    else:\n",
    "        results[i] = r\n",
    "    print(r)\n",
    "np.savetxt('results.txt',results)\n",
    "\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2746c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Good Runs = 1342\n",
      "N Bad Runs = 3658\n"
     ]
    }
   ],
   "source": [
    "results = np.loadtxt('../scripts/results.txt') # load our results\n",
    "good_results = []                   # the data that worked\n",
    "bad_results  = []                   # the data that did not, this now has error codes\n",
    "\n",
    "for i in range(len(results)):\n",
    "    metrics = results[i,1:]\n",
    "    if( (metrics<=0.).all() ):\n",
    "        bad_results.append(results[i,0])\n",
    "    else:\n",
    "        good_results.append(metrics)\n",
    "print('N Good Runs = {}'.format(len(good_results)))\n",
    "print('N Bad Runs = {}'.format(len(bad_results)))\n",
    "np.savetxt('bad_results.txt',bad_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "976290f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed no burn in\n",
      "Removed no burn in\n",
      "Removed no burn in\n",
      "Removed no burn in\n",
      "[0.41631434 1.71842019]\n",
      "[0.25313112 1.46306053]\n",
      "[0.         3.11088415]\n",
      "[0.18851877 1.2354045 ]\n"
     ]
    }
   ],
   "source": [
    "good_results_T = np.transpose(good_results)\n",
    "chain1 = getdist.MCSamples(samples=np.array(good_results_T[0]),names=['nf'],labels=['NF'])\n",
    "chain2 = getdist.MCSamples(samples=np.array(good_results_T[1]),names=['Q_UDM'],labels=['Q_{UDM}'])\n",
    "chain3 = getdist.MCSamples(samples=np.array(good_results_T[2]),names=['Q_DMAP'],labels=['Q_{DMAP}'])\n",
    "chain4 = getdist.MCSamples(samples=np.array(good_results_T[3]),names=['eigen'],labels=['Eigentension'])\n",
    "\n",
    "#limits and means\n",
    "mean_nf = chain1.getMeans()\n",
    "lims_nf = chain1.twoTailLimits(0, 0.67)\n",
    "lims_nf2 = chain1.twoTailLimits(0,0.95)\n",
    "lims_nf3 = chain1.twoTailLimits(0,0.997)\n",
    "print(lims_nf)\n",
    "\n",
    "mean_qudm = chain2.getMeans()\n",
    "lims_qudm = chain2.twoTailLimits(0, 0.67)\n",
    "lims_qudm2 = chain2.twoTailLimits(0,0.95)\n",
    "lims_qudm3 = chain2.twoTailLimits(0,0.997)\n",
    "print(lims_qudm)\n",
    "\n",
    "mean_qdmap = chain3.getMeans()\n",
    "lims_qdmap = chain3.twoTailLimits(0, 0.67)\n",
    "lims_qdmap2 = chain3.twoTailLimits(0,0.95)\n",
    "lims_qdmap3 = chain3.twoTailLimits(0,0.997)\n",
    "print(lims_qdmap)\n",
    "\n",
    "mean_eigen = chain4.getMeans()\n",
    "lims_eigen = chain4.twoTailLimits(0, 0.67)\n",
    "lims_eigen2 = chain4.twoTailLimits(0, 0.95)\n",
    "lims_eigen3 = chain4.twoTailLimits(0, 0.997)\n",
    "print(lims_eigen)\n",
    "\n",
    "x = np.arange(1,5,1)\n",
    "mean = np.mean([mean_nf,mean_qudm,mean_qdmap,mean_eigen])\n",
    "\n",
    "plt.plot(x[0],mean_nf,'b',marker='o',lw=0,label='Param Diff + NF')\n",
    "plt.plot([x[0],x[0]],[lims_nf[0],lims_nf[1]],c='b')\n",
    "#plt.plot([x[0],x[0]],[lims_nf2[0],lims_nf2[1]],'b--')\n",
    "#plt.plot([x[0],x[0]],[lims_nf3[0],lims_nf3[1]],'b:')\n",
    "\n",
    "plt.plot(x[1],mean_qudm,'g',marker='o',lw=0,label='$Q_{UDM}$')\n",
    "plt.plot([x[1],x[1]],[lims_qudm[0],lims_qudm[1]],c='g')\n",
    "#plt.plot([x[1],x[1]],[lims_qudm2[0],lims_qudm2[1]],'g--')\n",
    "#plt.plot([x[1],x[1]],[lims_qudm3[0],lims_qudm3[1]],'g:')\n",
    "\n",
    "plt.plot(x[2],mean_qdmap,'c',marker='o',lw=0,label='$Q_{DMAP}$')\n",
    "plt.plot([x[2],x[2]],[lims_qdmap[0],lims_qdmap[1]],c='c')\n",
    "#plt.plot([x[2],x[2]],[lims_qdmap2[0],lims_qdmap2[1]],'c--')\n",
    "#plt.plot([x[2],x[2]],[lims_qdmap3[0],lims_qdmap3[1]],'c:')\n",
    "\n",
    "plt.plot(x[3],mean_eigen,marker='o',c='r',lw=0,label='Eigentension + NF')\n",
    "plt.plot([x[3],x[3]],[lims_eigen[0],lims_eigen[1]],'r')\n",
    "#plt.plot([x[3],x[3]],[lims_eigen2[0],lims_eigen2[1]],'r--')\n",
    "#plt.plot([x[3],x[3]],[lims_eigen3[0],lims_eigen3[1]],'r:')\n",
    "\n",
    "#plt.plot(0,0,ls='-',c='k',label='CL=0.67')\n",
    "#plt.plot(0,0,ls='--',c='k',label='CL=0.95')\n",
    "#plt.plot(0,0,ls=':',c='k',label='CL=0.997')\n",
    "\n",
    "x = np.array([1,2,3,4,5,6])\n",
    "my_xticks = ['NF','$Q_\\mathrm{UDM}$','$Q_\\mathrm{DMAP}$','Eigen','','']\n",
    "plt.xticks(x, my_xticks)\n",
    "plt.plot([0.9,6.5],[mean,mean],'k-.',label='mean n_sigma')\n",
    "plt.ylabel('$n_\\sigma$')\n",
    "plt.xlim([0.9, 6.5])\n",
    "plt.legend()\n",
    "plt.savefig('metrics.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae8d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(chain1.samples,bins=np.arange(0,4,0.25),density=True)\n",
    "plt.plot([1.07220,1.07220],[0,1.0]) # 1.07220 is fiducial nf result\n",
    "plt.xlabel('$n_\\sigma$ NF')\n",
    "plt.savefig('nf_hist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48dd2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(chain2.samples,bins=np.arange(0,4,0.25),density=True)\n",
    "#plt.plot([1.07220,1.07220],[0,1.0]) # 1.07220 is fiducial nf result\n",
    "plt.xlabel('$n_\\sigma$ Q_{UDM}')\n",
    "plt.savefig('qudm_hist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949bd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(chain3.samples,bins=np.arange(0,4,0.25),density=True)\n",
    "#plt.plot([1.07220,1.07220],[0,1.0]) # 1.07220 is fiducial nf result\n",
    "plt.xlabel('$n_\\sigma$ Q_{DMAP}')\n",
    "plt.savefig('qdmap_hist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febd4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(chain4.samples,bins=np.arange(0,4,0.25),density=True)\n",
    "plt.plot([1.45829,1.45829],[0,1.5]) # 1.45829 is fiducial eigenmode result\n",
    "plt.xlabel('$n_\\sigma$ Eigen')\n",
    "plt.savefig('eigen_hist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff899f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emu",
   "language": "python",
   "name": "emu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
